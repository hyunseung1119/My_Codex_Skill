---
name: ml-training
description: ML/AI ëª¨ë¸ í•™ìŠµ, í‰ê°€, RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤. "ëª¨ë¸ í•™ìŠµ", "íŒŒì¸íŠœë‹", "ì„ë² ë”©", "ë²¡í„° ê²€ìƒ‰", "ëª¨ë¸ í‰ê°€", "ë°ì´í„°ì…‹", "ML training", "fine-tuning", "embeddings", "model evaluation", "dataset" ë“±ì˜ ìš”ì²­ ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤. LLM í†µí•©, ì„ë² ë”© ìƒì„±, ê²€ìƒ‰ ì‹œìŠ¤í…œ ê°œë°œì„ í¬í•¨í•©ë‹ˆë‹¤.
allowed-tools: Read, Write, Edit, Bash
---

# ML/AI ê°œë°œ ê°€ì´ë“œ

## ğŸ“‹ ê°œë°œ í”„ë¡œì„¸ìŠ¤

1. **ë°ì´í„° ì¤€ë¹„**: í•™ìŠµ/í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶•
2. **ëª¨ë¸ ì„¤ê³„**: ì•„í‚¤í…ì²˜ ì„ íƒ ë° êµ¬ì„±
3. **í•™ìŠµ/í‰ê°€**: ëª¨ë¸ í›ˆë ¨ ë° ì„±ëŠ¥ ì¸¡ì •
4. **ìµœì í™”**: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ì„±ëŠ¥ ê°œì„ 
5. **ë°°í¬**: í”„ë¡œë•ì…˜ í™˜ê²½ ì¤€ë¹„

## ğŸ¯ ML ê°œë°œ ì›ì¹™ (2026 Best Practices)

### í•„ìˆ˜ ì›ì¹™
- âœ… **ì¬í˜„ ê°€ëŠ¥ì„±**: Random seed ê³ ì •, ë²„ì „ ê´€ë¦¬
- âœ… **í‰ê°€ ë©”íŠ¸ë¦­**: ì •ëŸ‰ì  ì„±ëŠ¥ ì¸¡ì •
- âœ… **ì‹¤í—˜ ì¶”ì **: MLflow, Weights & Biases í™œìš©
- âœ… **ë°ì´í„° ë²„ì „ ê´€ë¦¬**: DVC ë˜ëŠ” Git LFS
- âœ… **ëª¨ë¸ ë²„ì „ ê´€ë¦¬**: ì²´í¬í¬ì¸íŠ¸ ì €ì¥

### ì„ íƒì  ê°œì„ 
- ğŸ”§ **ë¶„ì‚° í•™ìŠµ**: Multi-GPU, Distributed training
- ğŸ”§ **ìë™í™”**: CI/CD for ML (MLOps)
- ğŸ”§ **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¶”ì 

## ğŸ“ ê¶Œì¥ íŒŒì¼ êµ¬ì¡°

```
ml_project/
â”œâ”€â”€ data/                   # ë°ì´í„°
â”‚   â”œâ”€â”€ raw/               # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/         # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ external/          # ì™¸ë¶€ ë°ì´í„°
â”œâ”€â”€ models/                # í•™ìŠµëœ ëª¨ë¸
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ final/
â”œâ”€â”€ notebooks/             # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ exploratory/       # íƒìƒ‰ì  ë¶„ì„
â”‚   â””â”€â”€ experiments/       # ì‹¤í—˜ ë…¸íŠ¸ë¶
â”œâ”€â”€ src/                   # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ data/             # ë°ì´í„° ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ data_loader.py
â”‚   â”œâ”€â”€ models/           # ëª¨ë¸ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â”œâ”€â”€ evaluation/       # í‰ê°€
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â””â”€â”€ utils/            # ìœ í‹¸ë¦¬í‹°
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ scripts/              # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ tests/                # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_data.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ configs/              # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ config.yaml
â””â”€â”€ requirements.txt      # ì˜ì¡´ì„±
```

## ğŸ› ï¸ ì£¼ìš” íŒ¨í„´

### 1. RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ

#### ê¸°ë³¸ RAG íŒŒì´í”„ë¼ì¸

```python
# src/rag/retriever.py
from typing import List, Dict, Any
import numpy as np
from sentence_transformers import SentenceTransformer

class VectorRetriever:
    """ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ê¸°"""

    def __init__(self, embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(embedding_model)
        self.documents = []
        self.embeddings = None

    def index_documents(self, documents: List[str]) -> None:
        """ë¬¸ì„œ ì¸ë±ì‹±"""
        self.documents = documents
        self.embeddings = self.model.encode(documents, convert_to_numpy=True)

    def retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        query_embedding = self.model.encode([query], convert_to_numpy=True)[0]

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self.embeddings, query_embedding) / (
            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)
        )

        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = np.argsort(similarities)[-top_k:][::-1]

        results = [
            {
                "text": self.documents[idx],
                "score": float(similarities[idx]),
                "index": int(idx)
            }
            for idx in top_indices
        ]

        return results


# src/rag/generator.py
from anthropic import Anthropic

class RAGGenerator:
    """RAG ìƒì„±ê¸°"""

    def __init__(self, api_key: str, model: str = "claude-3-sonnet-20240229"):
        self.client = Anthropic(api_key=api_key)
        self.model = model

    def generate(
        self,
        query: str,
        contexts: List[str],
        system_prompt: str = "You are a helpful assistant."
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        # ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        context_text = "\n\n".join([f"Context {i+1}: {ctx}" for i, ctx in enumerate(contexts)])

        user_prompt = f"""Based on the following contexts, answer the question.

Contexts:
{context_text}

Question: {query}

Answer:"""

        response = self.client.messages.create(
            model=self.model,
            max_tokens=1024,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt}
            ]
        )

        return response.content[0].text


# src/rag/rag_system.py
class RAGSystem:
    """í†µí•© RAG ì‹œìŠ¤í…œ"""

    def __init__(self, retriever: VectorRetriever, generator: RAGGenerator):
        self.retriever = retriever
        self.generator = generator

    def query(self, query: str, top_k: int = 3) -> Dict[str, Any]:
        """RAG ì§ˆì˜"""
        # 1. ê²€ìƒ‰
        retrieved_docs = self.retriever.retrieve(query, top_k=top_k)
        contexts = [doc["text"] for doc in retrieved_docs]

        # 2. ìƒì„±
        answer = self.generator.generate(query, contexts)

        return {
            "query": query,
            "answer": answer,
            "sources": retrieved_docs
        }
```

### 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Keyword + Semantic)

```python
# src/rag/hybrid_retriever.py
from typing import List, Dict, Any
import numpy as np
from rank_bqm import rank_bm25

class HybridRetriever:
    """í‚¤ì›Œë“œ + ì‹œë§¨í‹± í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""

    def __init__(self, vector_retriever: VectorRetriever, alpha: float = 0.5):
        self.vector_retriever = vector_retriever
        self.bm25 = None
        self.alpha = alpha  # ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜

    def index_documents(self, documents: List[str]) -> None:
        """ë¬¸ì„œ ì¸ë±ì‹±"""
        # ë²¡í„° ì¸ë±ì‹±
        self.vector_retriever.index_documents(documents)

        # BM25 ì¸ë±ì‹±
        tokenized_docs = [doc.split() for doc in documents]
        self.bm25 = rank_bm25.BM25Okapi(tokenized_docs)

    def retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        # ë²¡í„° ê²€ìƒ‰
        vector_results = self.vector_retriever.retrieve(query, top_k=top_k * 2)

        # BM25 ê²€ìƒ‰
        tokenized_query = query.split()
        bm25_scores = self.bm25.get_scores(tokenized_query)

        # ìŠ¤ì½”ì–´ ì •ê·œí™” ë° ê²°í•©
        combined_scores = {}
        for result in vector_results:
            idx = result["index"]
            vector_score = result["score"]
            bm25_score = bm25_scores[idx]

            # ì •ê·œí™” (0-1 ë²”ìœ„)
            normalized_bm25 = bm25_score / (bm25_scores.max() + 1e-8)

            # ê°€ì¤‘ í‰ê· 
            combined_scores[idx] = (
                self.alpha * vector_score +
                (1 - self.alpha) * normalized_bm25
            )

        # ìƒìœ„ kê°œ ì„ íƒ
        top_indices = sorted(combined_scores.keys(), key=lambda x: combined_scores[x], reverse=True)[:top_k]

        results = [
            {
                "text": self.vector_retriever.documents[idx],
                "score": combined_scores[idx],
                "index": idx
            }
            for idx in top_indices
        ]

        return results
```

### 3. Reranker íŒ¨í„´

```python
# src/rag/reranker.py
from typing import List, Dict, Any
from sentence_transformers import CrossEncoder

class Reranker:
    """ì¬ìˆœìœ„í™” ëª¨ë¸"""

    def __init__(self, model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
        self.model = CrossEncoder(model_name)

    def rerank(
        self,
        query: str,
        documents: List[Dict[str, Any]],
        top_k: int = 3
    ) -> List[Dict[str, Any]]:
        """ë¬¸ì„œ ì¬ìˆœìœ„í™”"""
        # ì¿¼ë¦¬-ë¬¸ì„œ ìŒ ìƒì„±
        pairs = [[query, doc["text"]] for doc in documents]

        # ì ìˆ˜ ì˜ˆì¸¡
        scores = self.model.predict(pairs)

        # ì¬ìˆœìœ„í™”
        for doc, score in zip(documents, scores):
            doc["rerank_score"] = float(score)

        reranked = sorted(documents, key=lambda x: x["rerank_score"], reverse=True)

        return reranked[:top_k]
```

### 4. í™˜ê°(Hallucination) ê°ì§€

```python
# src/evaluation/hallucination_detector.py
from typing import List, Dict, Any
import re

class HallucinationDetector:
    """LLM í™˜ê° ê°ì§€"""

    def detect(
        self,
        answer: str,
        contexts: List[str],
        threshold: float = 0.7
    ) -> Dict[str, Any]:
        """í™˜ê° ê°ì§€"""
        # ë‹µë³€ì—ì„œ ì£¼ìš” ì£¼ì¥ ì¶”ì¶œ
        claims = self._extract_claims(answer)

        # ê° ì£¼ì¥ì˜ ê·¼ê±° í™•ì¸
        unsupported_claims = []
        for claim in claims:
            if not self._is_supported(claim, contexts, threshold):
                unsupported_claims.append(claim)

        is_hallucinated = len(unsupported_claims) > 0

        return {
            "is_hallucinated": is_hallucinated,
            "unsupported_claims": unsupported_claims,
            "total_claims": len(claims),
            "support_rate": 1 - (len(unsupported_claims) / max(len(claims), 1))
        }

    def _extract_claims(self, text: str) -> List[str]:
        """ì£¼ì¥ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬)"""
        sentences = re.split(r'[.!?]\s+', text)
        return [s.strip() for s in sentences if len(s.strip()) > 10]

    def _is_supported(self, claim: str, contexts: List[str], threshold: float) -> bool:
        """ì£¼ì¥ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ”ì§€ í™•ì¸"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• í•„ìš”)
        claim_words = set(claim.lower().split())

        for context in contexts:
            context_words = set(context.lower().split())
            overlap = len(claim_words.intersection(context_words))
            similarity = overlap / len(claim_words) if claim_words else 0

            if similarity >= threshold:
                return True

        return False
```

### 5. í‰ê°€ ë©”íŠ¸ë¦­

```python
# src/evaluation/metrics.py
from typing import List, Dict, Any
import numpy as np
from sklearn.metrics import precision_recall_fscore_support

class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ í‰ê°€"""

    @staticmethod
    def context_precision(
        retrieved_docs: List[Dict],
        relevant_docs: List[str],
        k: int = 5
    ) -> float:
        """Context Precision@K"""
        retrieved_ids = [doc["index"] for doc in retrieved_docs[:k]]
        relevant_count = sum(1 for doc_id in retrieved_ids if doc_id in relevant_docs)
        return relevant_count / k if k > 0 else 0.0

    @staticmethod
    def context_recall(
        retrieved_docs: List[Dict],
        relevant_docs: List[str]
    ) -> float:
        """Context Recall"""
        if not relevant_docs:
            return 0.0

        retrieved_ids = [doc["index"] for doc in retrieved_docs]
        relevant_count = sum(1 for doc_id in relevant_docs if doc_id in retrieved_ids)
        return relevant_count / len(relevant_docs)

    @staticmethod
    def mean_reciprocal_rank(
        retrieved_docs: List[Dict],
        relevant_docs: List[str]
    ) -> float:
        """Mean Reciprocal Rank"""
        for rank, doc in enumerate(retrieved_docs, 1):
            if doc["index"] in relevant_docs:
                return 1.0 / rank
        return 0.0

    @staticmethod
    def ndcg_at_k(
        retrieved_docs: List[Dict],
        relevance_scores: Dict[str, float],
        k: int = 5
    ) -> float:
        """Normalized Discounted Cumulative Gain@K"""
        dcg = 0.0
        for rank, doc in enumerate(retrieved_docs[:k], 1):
            relevance = relevance_scores.get(doc["index"], 0.0)
            dcg += (2 ** relevance - 1) / np.log2(rank + 1)

        # IDCG (Ideal DCG)
        ideal_relevances = sorted(relevance_scores.values(), reverse=True)[:k]
        idcg = sum(
            (2 ** rel - 1) / np.log2(rank + 1)
            for rank, rel in enumerate(ideal_relevances, 1)
        )

        return dcg / idcg if idcg > 0 else 0.0
```

### 6. ì‹¤í—˜ ì¶”ì  (MLflow)

```python
# scripts/train_with_tracking.py
import mlflow
import mlflow.sklearn
from src.models.model import MyModel

def train_with_tracking():
    """MLflowë¡œ ì‹¤í—˜ ì¶”ì """

    # ì‹¤í—˜ ì„¤ì •
    mlflow.set_experiment("rag-optimization")

    with mlflow.start_run(run_name="hybrid-retrieval-v1"):
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        params = {
            "embedding_model": "all-MiniLM-L6-v2",
            "alpha": 0.5,  # í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜
            "top_k": 5,
            "reranker": "cross-encoder",
        }
        mlflow.log_params(params)

        # ëª¨ë¸ í•™ìŠµ
        model = MyModel(**params)
        model.train(data)

        # ë©”íŠ¸ë¦­ ë¡œê¹…
        metrics = evaluate_model(model)
        mlflow.log_metrics({
            "precision@5": metrics["precision"],
            "recall@5": metrics["recall"],
            "mrr": metrics["mrr"],
            "latency_ms": metrics["latency"]
        })

        # ëª¨ë¸ ì €ì¥
        mlflow.sklearn.log_model(model, "model")

        # ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
        mlflow.log_artifact("results/confusion_matrix.png")

    print(f"Run completed. View at: {mlflow.get_tracking_uri()}")
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. í† í° íš¨ìœ¨ì„±

```python
# í”„ë¡¬í”„íŠ¸ ì••ì¶•
def compress_context(contexts: List[str], max_tokens: int = 2000) -> str:
    """ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
    compressed = []
    total_tokens = 0

    for ctx in contexts:
        tokens = len(ctx.split())  # ê°„ë‹¨í•œ í† í° ì¶”ì •
        if total_tokens + tokens > max_tokens:
            break
        compressed.append(ctx)
        total_tokens += tokens

    return "\n\n".join(compressed)


# ìºì‹±
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_embeddings(text: str) -> np.ndarray:
    """ì„ë² ë”© ìºì‹±"""
    return model.encode([text])[0]
```

### 2. ë°°ì¹˜ ì²˜ë¦¬

```python
# ë³‘ë ¬ ì²˜ë¦¬
import asyncio
from typing import List

async def process_batch(queries: List[str], batch_size: int = 10) -> List[Dict]:
    """ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬"""
    results = []

    for i in range(0, len(queries), batch_size):
        batch = queries[i:i + batch_size]
        tasks = [rag_system.query(q) for q in batch]
        batch_results = await asyncio.gather(*tasks)
        results.extend(batch_results)

    return results
```

### 3. ì¸ë±ìŠ¤ ìµœì í™”

```python
# FAISS ë²¡í„° ì¸ë±ìŠ¤
import faiss

class FAISSRetriever:
    """FAISS ê¸°ë°˜ ê³ ì† ê²€ìƒ‰"""

    def __init__(self, embedding_dim: int = 384):
        self.index = faiss.IndexFlatL2(embedding_dim)
        self.documents = []

    def index_documents(self, documents: List[str], embeddings: np.ndarray) -> None:
        """ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì¸ë±ì‹±"""
        self.documents = documents
        self.index.add(embeddings.astype('float32'))

    def retrieve(self, query_embedding: np.ndarray, top_k: int = 5) -> List[Dict]:
        """ê³ ì† ê²€ìƒ‰"""
        distances, indices = self.index.search(
            query_embedding.astype('float32').reshape(1, -1),
            top_k
        )

        results = [
            {
                "text": self.documents[idx],
                "score": 1 / (1 + float(dist)),  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                "index": int(idx)
            }
            for idx, dist in zip(indices[0], distances[0])
        ]

        return results
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° í‰ê°€

```bash
# ëª¨ë¸ í•™ìŠµ
python scripts/train.py --config configs/config.yaml

# í‰ê°€
python scripts/evaluate.py --model models/best_model.pt --test-data data/test.jsonl

# ì¶”ë¡ 
python scripts/predict.py --input "Your query here"

# MLflow UI ì‹¤í–‰
mlflow ui --port 5000
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [LangChain ë¬¸ì„œ](https://python.langchain.com/)
- [FAISS ë¬¸ì„œ](https://faiss.ai/)
- [MLflow ë¬¸ì„œ](https://mlflow.org/docs/latest/index.html)
